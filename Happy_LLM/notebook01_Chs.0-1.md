#### Chapter 00
##### LLM发展
```
 LLM 发展
├── NLP 历史演进
│   ├── 符号主义阶段
│   ├── 统计学习阶段
│   ├── 深度学习阶段
│   ├── 预训练模型阶段（PLM）
│   └── 大模型阶段（LLM）
│
├── PLM（上一阶段核心成果）
│   ├── 代表：GPT、BERT
│   ├── 架构：注意力机制
│   ├── 方法：预训练 + 微调
│   │   └─ 海量无监督文本 → 自监督预训练
│   ├── 优势：强大自然语言理解能力
│   └── 局限
│       ├── 依赖一定量有监督数据微调
│       ├── 生成任务性能不尽如人意
│       └── 距通用人工智能仍有差距
│
├── LLM（PLM 的衍生成果 & 突破）
│   ├── 实现手段
│   │   ├── 大量扩大模型参数
│   │   ├── 扩大预训练数据规模
│   │   ├── 指令微调
│   │   └── 人类反馈强化学习（RLHF）
│   ├── 核心能力（相较 PLM 的突破）
│   │   ├── 涌现能力
│   │   ├── 强大上下文学习能力
│   │   ├── 指令理解能力
│   │   └── 强大文本生成能力
│   └── 研究范式转变
│       ├── 减少对大量监督标注依赖
│       ├── 少量示例 → 媲美大规模微调性能
│       └── 直接、高效、准确响应用户指令
│
└── LLM 阶段现状与未来（2023 年至今)
    ├── 阶段性成果层出不穷
       ├── ChatGPT
       ├── GPT-4
       ├── 推理大模型（代表：DeepSeek-R1）
       └── 多模态大模型（代表：Qwen-VL）
```
---
#### Chapter 01
